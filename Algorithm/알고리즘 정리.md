# 알고리즘 정리

[TOC]

## 배열

### 01. 완전검색

- 문제의 해법으로 생각할 수 있는 모든 경우의 수를 나열해보고 확인하는 기법

  - Brute-force 혹은 gernerate-and-test 기법이라고도 부름
  - 모든 경우의 수를 테스트한 후, 최종 해법을 도출

- 일반적으로 경우의 수가 상대적으로 작을 때 유용함

  - 모든 경우의 수를 생성하고 테스트하기 때문에 수행 속도는 느리지만, 해답을 못 찾는 경우는 없음

- (중복) 순열, (중복) 조합, 부분집합 등의 방법으로 경우의 수를 만들어 냄

- 완전 검색으로 접근하여 해답을 도출 한 후, 성능 개선을 위해 다른 알고리즘을 사용하는게 바람직

- 관련 문제

  - Baby-gin

  

### 02. 탐욕(Greedy) 알고리즘

- 최적해를 구하는데 사용되는 근시안적인 방법

  - 하나를 결정할 때마다 최적이라 생각되는 것을 선택해 나가는 방식으로 진행하여 해답 도출

- 각 선택의 시점에서는 최적이지만 그 선택들을 계속 수집하여 최종적인 해답을 만들었다고 하여, 그것이 최적이라는 보장은 없음

  - 그러나 성능이 좋기 때문에 반례까지 해결한 것을 증명해내면 안전하게 사용할 수 있음

- 일반적으로, 머릿속에 떠오르는 생각을 검증 없이 바로 구현하면 Greedy 접근이 됨

- 동작과정

  ```
  1) 해 선택 : 현재 상태에서 부분 문제의 최적 해를 구한 뒤, 이를 부분해 집합(Solution Set)에 추가한다.
  2) 실행 가능성 검사 : 새로운 부분해 집합이 실행 가능한지를 확인한다. 곧, 문제의 제약조건을 위반하지 않는지를 검사한다.
  3) 해 검사 : 새로운 부분해 집합이 문제의 해가 되는지를 확인한다. 아직 전체 문제의 해가 완성되지 않았다면 1)의 해 선택부터 다시 시작한다.
  ```

- 관련문제

  - 거스름돈 줄이기



### 03. 버블 정렬(Bubble Sort)

- 인접한 두 개의 원소를 비교하며 자리를 계속 교환하는 방식

  - 교환하며 자리를 이동하는 모습이 물 위에 올라오는 거품 모양과 같다고 하여 버블정렬이라고 함

- 동작과정

  ```
  1) 첫 번째 원소부터 인접한 원소끼리 계속 자리를 교환하면서 맨 마지막 자리까지 이동한다.
  2) 한 단계가 끝나면 가장 큰 원소가 마지막 자리로 정렬된다.
  ```

- 시간 복잡도

  - O(n^2)

- 코드

  ```python
  def BubbleSort(arr):
      for i in range(len(arr)):
          for j in range(len(arr)-i):
              if arr[j]>arr[j+1]:
                  arr[j],arr[j+1]=arr[j+1],arr[j]
  ```

  

### 04. 카운팅 정렬(Counting Sort)

- 항목들의 순서를 결정하기 위해 집합에 각 항목이 몇 개씩 있는지 세는 작업을 하여, 선형 시간에 정렬하는 효율적인 알고리즘

- 제한사항

  ```
  1) 정수나 정수로 표현할 수 있는 자료에 대해서만 적용 가능 : 각 항목의 발생 회수를 기록하기 위해, 정수 항목으로 인덱스 되는 카운트들의 배열을 사용하기 때문
  2) 카운트들을 위한 충분한 공간을 할당하려면 집합 내의 가장 큰 정수를 알아야 한다.
  ```

- 시간복잡도

  - O(n+k) : n은 리스트 길이, k는 정수의 최대값

- 코드

  ```python
  def CountingSort(arr,b,k):
      c=[0]*k
      for i in range(0,len(b)):
          c[arr[i]]+=1
      for i in range(1,len(c)):
          c[i]+= c[i-1]
      for i in range(len(b)-1,-1,-1):
          b[c[arr[i]]-1]=A[i]
          c[arr[i]]-=1
  ```

  

### 05. 비트연산자

- << (shift) 연산자 
  - 1<<n : 2^n, 즉 원소가 n개일 경우의 모든 부분집합의 수를 의미한다.
  -  i&(1<<j) : i의 j번째 비트가 1인지 아닌지 리턴한다.
- 관련문제

  - 부분집합 구하기

- 코드

  ```python
  def PartsSet(n,arr): # n은 arr의 원소의 수
      result=[]
      for i in range(1<<n):
          part=[]
          for j in range(n):
              if i&(1<<j):
                  part.append(arr[j])
         	result.append(part)
      return result
  ```

- XOR(^)을 이용해서 `a=a^b; b=a^b; a=a^b`로 swap을 구현할 수 있다.

### 06. 순차 검색(Sequential Search)

- 일렬로 되어있는 자료를 순서대로 검색하는 방법

  - 가장 간단하고 직관적인 검색 방법
  - 배열이나 연결 리스트 등 순차구조로 구현된 자료구조에서 원하는 항목을 찾을 때 유용함
  - 구현이 쉬우나 검색 대상의 수가 많은 경우에는 수행시간이 급격히 증가하여 비효율적임

- 정렬되어 있지 않은 경우

  - 처음부터 끝까지 일일히 검사하기 때문에 찾고자 하는 원소의 순서에 따라 비교회수가 결정

  - 코드

    ```python
    def SequentialSearch1 (arr,n,key):
        i=0
        while i<n and arr[i]<key:
            i+=1
        if i<n :
            return i
        else :
            return -1
    ```

- 정렬되어 있는 경우

  - 키 값을 비교하며 원소의 키 값이 검색 대상의 키 값보다 크면 찾는 원소가 없는 것으로 더 이상 검색하지 않고 검색을 종료함

  - 코드

    ```python
    def SequentialSearch2 (a,n,key):
        i=0
      	while i<n and a[i]<key:
            i+=1
        if i<n and a[i]==key:
            return i
        else :
            return -1
    ```

- 시간복잡도

  - O(n)



### 07. 이진 검색(Binary Search)

- 자료의 가운데에 있는 항목의 키 값과 비교하여 다음 검색의 위치를 결정하고 검색을 계속 진행하는 방법

  - 목적 키를 찾을 때까지 이진 검색을 순환적으로 반복 수행함으로써 검색 범위를 반으로줄여가면서 보다 빠르게 검색을 수행함

- 제한사항

  ```
  이진 검색을 하기 위해서는 자료가 정렬된 상태여야 한다.
  ```

- 동작과정

  ```
  1) 자료의 중앙에 있는 원소를 고른다.
  2) 중앙 원소의 값과 찾고자 하는 목표 값을 비교한다.
  3) 목표 값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행하고, 크다면 자료의 오른쪽 반에 대해서 새로 검색을 수행한다.
  4) 찾고자 하는 값을 찾을 때까지 1)~3)의 과정을 반복한다.
  ```

- 코드

  ```python
  # 반복문
  def BinarySearch1(arr,key):
      start=0
      end=len(arr)-1
      while start<=end:
          middle=(start+end)//2
          if arr[middle]==key:
              return true
          elif arr[middle]>key:
              end=middle-1
          else:
              start=middle+1
  	return false
  # 재귀
  def BinarySearch2(arr,start,end,key):
      if start>end:
          return False
      else :
          middle=(start+end)//2
          if arr[middle]==key:
              return true
          elif arr[middle]>key:
              return BinarySearch2(arr,start,middle-1,key)
          else:
              return BinarySearch2(arr,middle+1,end,key)
  	return false
  ```

  

### 08. 인덱스

- 테이블에 대한 동작 속도를 높여주는 자료 구조를 말함
  - 대량의 데이터를 매번 정렬하면 프로그램의 반응이 느려지기에 이를 해결해줌
- 인덱스는 key-field만 갖고 있기에 저장 공간이 테이블보다 작음



### 09. 셀렉션 알고리즘(Selection Algorithm)

- 저장되어 있는 자료로부터 k번째로 큰 혹은 작은 원소를 찾는 방법

  - 최소값, 최대값 혹은 중간값을 찾는 알고리즘을 의미하기도 함

- 동작과정

  ```
  1) 정렬 알고리즘을 이용하여 자료 정렬하기
  2) 원하는 순서에 있는 원소 가져오기
  ```

- 코드

  ```python
  def SelectionAlgorithm(arr,k):
      for i in range(0,k):
      	minIdx=i
          for j in range(i+1,len(arr)):
              if arr[minIdx]>arr[j]:
              	minIdx=j
                  arr[minIdx],arr[j]=arr[j],arr[minIdx]
      return arr[k-1]
  ```

- 시간복잡도

  - O(k*n)



### 10. 선택 정렬(Selection Sort)

- 주어진 자료들 중 가장 작은 값의 원소부터 차례대로 선택하여 위치를 교환하는 방식

  - 셀렉션 알고리즘을 전체 자료에 적용

- 동작과정

  ```
  1) 주어진 리스트 중에서 최소값을 찾는다.
  2) 그 값을 리스트의 맨 앞에 위치한 값과 교환한다.
  3) 맨 처음 위치를 제외한 나머지 리스트를 대상으로 위의 과정을 반복한다.
  ```

- 시간복잡도

  - O(n^2)

- 코드

  ```python
  def SelectionAlgorithm(arr):
      for i in range(0,len(arr)-1):
      	minIdx=i
          for j in range(i+1,len(arr)):
              if arr[minIdx]>arr[j]:
              	minIdx=j
                  arr[minIdx],arr[j]=arr[j],arr[minIdx]
      return arr
  ```

  

## 문자열

### 01. 문자열

- 아스키 코드
  - A(65)~Z(90), a(97)~z(122)
  - 표준 아스키는 세계적으로 통용되어 있지만 확장 아스키는 디바이스가 그것을 해독할 수 있도록 설계되어 있어야함
- endian
  - big-endian
    - 값을 뒤 쪽에 작성
    - 워크스테이션에서 사용되며 디버깅이 편리하고 비교연산에서 빠름
  - little-endian
    - 값을 앞 쪽에 작성
    - 메모리에 저장된 하위 바이트들만 사용할 때 별도의 계산이 필요없음
    - 산술연산에서 빠름



### 02. 패턴 매칭

#### 01) 고지식한 패턴 검색 알고리즘(Brute Force)

- 문자열을 처음부터 끝까지 차례대로 순회하면서 패턴 내의 문자들을 일일이 비교하는 방식으로 동작

- 코드

  ```python
  def BruteForce(arr,search):
      m=len(arr)
      n=len(search)
      i=0
      j=0
      while i<m and j<n:
          if arr[i] != search[j]:
              i=i-j # j는 i가 움직인 거리로 백업변수를 사용하지 않고 구현
              j=-1
          i+=1
          j+=1
      if j==m:
          return i-m # 일지하는 문자열의 시작위치 리턴
      else:
          return -1
  ```

- 시간복잡도

  - O(m*n)

#### 02) 카프-라빈 알고리즘(Rabin-Karp Algorithm)

- 문자열을 수치로 변환시켜 탐색하는 일대일 매칭 알고리즘

- 해시 함수를 통해 나온 결과를 인덱스로 하여 해시테이블에 저장하는 해싱(Hashing)방식을 기반으로 함

  - 충돌이 편향적으로 심각하게 발생하면 군집화(clustering)이 일어나 효율이 떨어짐

  - 충돌하는 값이 많으면 해당 인덱스 값을 모두 찾는데에 시간이 많이 소요됨

  - 해시 함수를 잘 만드는 것이 가장 중요

  - 주로 `Rabin fingerprint`가 사용됨 (함수 S는 아스키 코드 변환 함수인  `ord` 사용)
    $$
    f(x)=m_0+m_1x+...+m_{n-1}x^{n-1}
    $$

    $$
     H[i]=S[i]*2^{M-1}+S[i+1]*2^{M-2}+...+S[i+M-2]*2^1+S[i+M-1]*2^0
    $$

    $$
    H[i+1]=2*(H[i]-S[i]*2^{M-1})+S[i+M]*2^0
    $$

- 동작과정

  ```
  1) 비교 대상 문자열에서 찾을 문자열의 길이만큼 한 칸씩 옮기며 해시함수를 이용해 숫자로 변환
  2) 찾을 문자열의 해시값과 일치한 값이 있는지 확인
  ```

- 시간복잡도

  - 해시 함수에 따라 다름

#### 03) KMP 알고리즘

- 불일치가 발생한 문자열 앞 부분에 어떤 문자가 있는지를 미리 알고 있으므로, 불일치가 발생한 앞 부분에 대하여 다시 비교하지 않고 매칭을 수행하는 알고리즘

- 패턴을 전처리하여 불일치가 발생할 경우 이동할 다음 위치를 구해서 잘못된 시작을 최소화함

  <img src="images/image 001.png"/>

  <img src="images/image 002.png"/>

- 시간복잡도

  - O(n)

#### 04) 보이어-무어 알고리즘

- 패턴 오른쪽 끝에 있는 문자가 불일치하고 이 문자가 패턴 내에 존재하지 않는 경우, 이동 거리는 패턴의 길이만큼 되는 알고리즘

  - 다른 알고리즘과 달리 텍스트 문자를 다 보지 않아도 됨

  <img src="images/image 003.png"/>
- 시간복잡도

  - 최선 : O(n), 최악 : O(m*n)



### 03. 문자열 암호화

#### 01) 시저 암호 (Caesar cipher)

- 평문에서 사용되고 있는 알파벳을 일정한 문자 수만큼 평행이동시킴으로써 암호화를 행함

#### 02) 단일 치환 암호

- 별도의 문자 변환표를 이용해 암호화

#### 03) bit열의 암호화

- 배타적 논리합(xor) 연산 사용



### 04. 문자열 압축

#### 01) Run-length encoding

- 같은 값이 몇 번 반복되는가를 나타냄으로써 압축
- 이미지 BMP 포맷의 압축방법

#### 02) 허프만 코딩 알고리즘



## 스택

### 01. 스택의 특성

- 1대1 관계를 갖는 선형 구조로 물건을 쌓아 올리듯 자료를 쌓아 올린 형태의 자료구조
- 후입선출(LIFO, Last-In-First-Out)
- 연산
  - 삽입 : push, 저장소에 자료를 저장함
  - 삭제 : pop, 저장소에서 사입한 자료의 역순으로 꺼냄
  - 공백 확인, isEmpty
  - 스택의 top에 있는 item(원소)을 반환하는 연산, peek
- 고려사항
  - 구현이 용이하나 스택의 크기를 변경하기 어려움
  - 동적 연결리스트로 효율적인 동적 할당이 가능하나 구현이 복잡함

- 응용

  - 괄호검사

  - Function call

    <img src="images/image 004.png"/>



### 02. 재귀호출

- 자기 자신을 호출하여 순환 수행되는 것

- 프로그램의 크기를 줄이고 간단하게 작성할 수 있음



### 03. Memoization

<img src="images/image 005.png"/>

  - 재귀호출은 많은 중복 호출이 존재하기에 성능을 높이기 위해 미리 저장한 이미 계산된 값을 불러오도록 함



### 04. DP(Dynamic Programming)

- 동적 계획, 그리디 알고리즘과 같이 최적화 문제를 해결하는 알고리즘
- 먼저 입력 크기가 작은 부분 문제들을 모두 해결한 후에 그 해들을 이용하여 보다 큰 크기의 부분 문제들을 해결하여, 최종적으로 원래 주어진 입력의 문제를 해결하는 알고리즘

<img src="images/image 006.png"/>



### 05. DFS(깊이우선탐색)

- 시작 정점의 한 방향으로 갈 수 있는 경로가 있는 곳까지 깊이 탐색해 가다가 더 이상 갈 곳이 없게 되면, 스택을 이용해 가장 마지막에 만났던 갈림길 간선이 있는 정점으로 되돌아와서 다른 방향의 정점으로 탐색을 계속 반복하여 결국 모든 정점을 방문하는 순회방법

